# NYTBestsellersAnalysis-PySpark

## Introduction
Welcome to the `NYTBestsellersAnalysis-PySpark` repository! This project presents an in-depth analysis of the New York Times Bestselling books, focusing on Hardcover Fiction from June 7, 2008, to July 22, 2018. Conducted using PySpark on a Databricks cluster, this analysis delivers insights into bestselling authors, publishers, and book trends.

## Repository Contents
- `NYT Books Analysis.ipynb`: A Jupyter Notebook containing the complete PySpark code used for data analysis. This notebook was executed on a Databricks cluster, ensuring efficient processing of large-scale data. It covers:
  - Data preparation, cleaning, and transformation
  - Bestselling Authors Analysis
  - Publisher Insights
  - Book Longevity Study
  - Author Rank Examination
  - Rank Analysis
- `nyt2.json`: The dataset in JSON format, including data on bestselling books as per the New York Times API.

## Getting Started
To use this repository:
1. **Clone the Repository**: 
   ```bash
   git clone https://github.com/Mankabir/PySparkNYTBestsellersAnalysis.git
   ```
2. **Install Requirements**: Ensure PySpark is installed in your Databricks environment. 
3. **Open the Notebook**: Upload `NYT Books Analysis.ipynb` to your Databricks workspace and attach it to a cluster.
4. **Explore the Data**: The notebook is well-commented and guides you through each analysis step.

## Prerequisites
- Databricks Workspace
- PySpark environment on Databricks
- Basic knowledge of PySpark and Databricks

## Usage
This repository is particularly useful for data analysts and scientists interested in literary trends and big data processing in a distributed environment. The analysis can serve as a foundation for understanding market dynamics in the publishing industry.

## Contributing
Contributions to enhance or extend this analysis are welcome. Please open an issue first to discuss your ideas.

## License
[MIT License](https://opensource.org/licenses/MIT) - free for use and modification.

## Acknowledgements
- New York Times for the API and data.
- Databricks and PySpark Communities for their powerful data processing tools.
